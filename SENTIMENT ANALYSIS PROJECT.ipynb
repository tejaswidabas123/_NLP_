{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "originalImage = cv2.imread('test4.png')\n",
    "\n",
    "img=cv2.GaussianBlur(originalImage, (1,1), 0)\n",
    "img=cv2.fastNlMeansDenoisingColored(img,None,10,0,20,71)\n",
    "#plt.imshow(img)\n",
    "grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  \n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(grayImage,190,240, cv2.THRESH_BINARY)\n",
    "#plt.imshow(blackAndWhiteImage)\n",
    "#plt.imshow(originalImage)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img2= Image.fromarray(blackAndWhiteImage)\n",
    "#plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "im = img2\n",
    "length_x, width_y = im.size\n",
    "factor = min(1, float(1024.0 / length_x))\n",
    "size = int(factor * length_x), int(factor * width_y)\n",
    "im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "temp_file = tempfile.NamedTemporaryFile(delete=False,suffix='.png')\n",
    "file= temp_file.name\n",
    "im_resized.save(file, dpi=(300, 300)) \n",
    "img = cv2.imread(file, 0)\n",
    "filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 41)\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "image = cv2.bitwise_or(img, closing)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "from pytesseract import image_to_string\n",
    "text=image_to_string(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\EESHITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text =  \"Where are my pizza rolls WOODY\"\n",
    "#text is what we ll obtain from our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text=sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'are', 'my', 'pizza', 'rolls', 'WOODY']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Where are my\\npizza rolls WOODY']\n",
      "Filtered Sentence: ['Where', 'pizza', 'rolls', 'WOODY']\n"
     ]
    }
   ],
   "source": [
    "filtered_word=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_word.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_text)\n",
    "print(\"Filtered Sentence:\",filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence ['Where', 'pizza', 'rolls', 'WOODY']\n",
      "Stemmed Sentence ['where', 'pizza', 'roll', 'woodi']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_words=[]\n",
    "for w in filtered_word:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "    \n",
    "print(\"Filtered Sentence\",filtered_word)\n",
    "print(\"Stemmed Sentence\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = [filtered_word[i:i+N] for i in range(len(filtered_word)-N+1)]\n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'pizza', 'rolls', 'WOODY']\n"
     ]
    }
   ],
   "source": [
    "for gram in grams: print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are my\n",
      "pizza rolls WOODY\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "for txt in tokenized_text:\n",
    "    print(txt)\n",
    "    analysis=TextBlob(txt)\n",
    "    print(analysis.sentiment)\n",
    "    if analysis.sentiment[0]>0:\n",
    "        print('Positive')\n",
    "    elif analysis.sentiment[0]<0:\n",
    "        print('Negative')\n",
    "    else:\n",
    "        print('neutral')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
